库存服务:
浏览器的等请求到商品服务,操作完后其实是设置了库存的,也就是商品服务会调用库存服务
订单服务会预扣库存和归还库存 支付服务会扣库存(支付宝调用支付服务)
库存一般提供给其他rpc服务调用,自身不用设置api层





并发情况下库存比如扣减库存容易出现问题,其实就是并发修改stock,可能多个调用这个库存微服务去扣减库存
解决并发问题,最原始的方式就是加锁
实际上就是要解决同一时间只能有一个服务操作同一件商品的库存,服务完成后再到别的进程处理
比如同时两个订单服务同时查询库存发现都是100件,都扣减1,大家更新库存都是99,而实际上应该是98,也就是卖两件,也就是一件商品当成出售两次,超卖
解决方式就是加分布式锁,得我这个订单服务查询库存更新库存完成后,再到别的进程处理
也就是让各个进程代码开始直接先去获取一把分布式锁,获取到锁的类似拿到令牌,才能进行后续的逻辑,服务完成释放锁
可以直接在服务的代码逻辑中加锁,但问题是这不是代码本身的goroutine,二十多个进程,每个进程(协程都获取一次这个局部锁,对自身并发有约束,但是对多进程并发没意义)
所以要在代码外部定义全局锁,然后服务代码逻辑中使用,在查询更新等数据库操作之前上锁,如果由事务要在事务之后释放锁
局部锁也就是服务代码中定义的锁除了没有多进程并发调用这个服务没有约束里,因为是服务代码中定义的,所以要共用一把锁(所以grpc并不是只是调用服务代码代码快本身,还有server端的很多内容),还有就是性能消耗问题
那全局锁,实际上使用也是服务代码中使用,比如上锁,锁是由资源消耗的,高并发情况下,还是获取大量的锁,性能消耗,比如请求的是多个商品的库存处理,这里就不是同一个临界资源stock了,而是不同商品所以都能获得相应的锁(一把实际的锁其实是针对某相同的一个或多个临界资源护或者说共享变量 共享内存地址被多个进程(协程)进行处理),那么就是同时多个进程都能对一把全局锁进行上锁,性能问题就来了
解决办法就是池化全局锁
那么这种锁在分布式系统中有什么问题呢,比如这个server端服务在多个机器上都有,也就是多个实例,而锁是依赖操作系统提供了,所以同一个机器上的多个服务协程调用可以通过同一把锁来解决,但不同机器上就不能通过这样一把锁来解决了,因为是同一类server端服务,很有可能同一个rpc是共用一个数据库,这时候不同机器还是存在资源竞争问题
单机锁就不够了,需要分布式锁,也就是在多个库存服务之间有个独立的分布式锁
也就是库存服务1中有服务被调用,不论是客户端多进程来调用,还是服务本身多goroutine运行,只要库存服务1在运行,也就是获取了分布式锁,那么别的库存服务就要等待
实际上也不用多机,哪怕是一台主机上多个进程,多个pod,多个容器都应该使用分布式锁才有效
第三方服务可以是mysql redis等,一般是共同使用的服务,提供了分布式锁



注意这里通过channel并不能很好处理,channel是不同goroutine之间传递信息,同步操作,而这里是不同的进程了,channel适合自身的代码内的并发设计,不同进程要使用分布式锁(可以将数据库中的数据拿到内存中,也就是一个变量,channel来协调多个goroutine来设置这个变量)
比如定义一个变量int,一个channel int,gorouine中使用这个变量,修改这个变量,将值写入channel,然后主goroutine读取channel值给变量
或者直接加锁
缓冲通道实际上就是多个缓冲,由元素就不阻塞,本质还是channel,同一时间只有一个goroutine在处理



------------------------------分布式锁的实现方案
1.基于mysql实现的分布式锁(乐观锁,悲观锁)
不是mysql的表锁,行锁等
悲观锁和乐观锁都是人为概念

悲观锁,也就是持有悲观态度,总觉得会冲突,总觉得获取或者修改数据时,别人也会修改数据,所以整个数据处理过程数据是锁定的
比如两个库存服务,实际上使用的都是一个数据库,a服务操作数据是,让数据库对这个数据锁上,某条数据或者某张表,也类似mutex,只不过是由mysql提供,其实就是互斥锁
实际上就是串行化了,

///////////////////////for update 实现悲观锁,但是每个语句悲观锁默认提交
select @@autocommit;
set autocommit=0//关闭悲观锁的默认提交,只是针对当前这次有效,让下面的for update还未提交
select @@autocommit;
select *from xxx where xxx=xxx for update  //  这样就锁了这条记录,这里其实是行锁,这锁住这条记录,注意如果这个where子弹没有索引,会升级为表锁
//还要注意一点只是锁住更新的语句,也就是你的新的查询测试语句不加for update不会被锁住,正常获取数据
//另外如果没有匹配到这条记录数据且由索引不会锁表,如果没有索引,不管什么情况直接锁表
commit  //释放锁

///////////////////////gorm基于mysql实现悲观锁




////////////////////////////////mysql的乐观锁
解决悲观锁的性能问题,也就是不加锁
可以通过一个字段来标识,比如version
其实就是更新的时候更新那个字段并且设置这个字段为过滤条件,肯定只有一个成功,因为微观角度就是只有一个成功执行,然后修改了版本号,另外的语句使用了这个version过滤条件的就会失败
update inv set stock=99,version=version+1 where commodityid=xxx and version=version(这个version一开始大家都可以select,然后将version放到临时变量中)
也就是更新之前其他的查到的version,它们做更新会失败,本质就是某个字段作为过滤条件同时每次更新都变更它,保证操作的是当时查询出来的记录,如果失败就重试
失败的就重新查询更新



2.基于redis实现分布式锁
https://github.com/go-redsync/redsync
定义一个key,服务访问的时候发现这个key没有设置那么就设置这个key的value,也就是获得锁,其他服务访问redis发现key被设置了,就不能获得锁,然后就轮循等待
完成了业务逻辑就释放锁,也就是删除key
需要setnx,也就是查询和设置一块做,确保原子性
setnx成功返回1,失败返回0
问题:
1.如果设置了锁,但是来不及释放锁就挂掉了,后续的服务一直拿不到锁,也就是死锁
解决方法,设置过期时间,但是如果业务还没执行完,锁就过期了,所以可以通过一个goroutine去刷新锁,也就是延时过期时间,但是还有问题,就是你hung住了,又不断刷新锁,导致别人申请不到锁
2.分布式锁的互斥性和死锁上面解决了,但是安全性,也就是锁应该只有上锁人也就是持有锁的才能解锁
解决方法就是拿到这个锁的key的值(随机值)和自己保存的值对比,一样才能删除,也就是持有锁的才能删除(场景就是服务a拿到锁但是过期了,别的服务就可以进来了,然后可以删除锁也就是进行redis命令行操作)

红锁redlock
如果是redis集群,服务可能从这个slave读取也就是获取所,也可能从另一个slave读取,对于写的时候会写master,集群内不会同步
但是如果master宕机了(网络故障,网络延迟,跟某台slave来不及同步,高并发下),数据来不及写来不及同步,slave来不及同步数据,服务b访问到某个未同步的slave,发现key没有被设置,那么也去获取锁,也就是设置写入锁

因此使用redlock,其实就是setnx要在所有的master和slave都执行才行,但是也有个情况,可能服务a setnx了一部分机器,服务b也来设置了一部分的机器了,所以这时候就看谁设置了n/2+1太,就是看谁设置的多谁就设置成功,所以redis集群一般都是奇数



使用的:
建立redis连接也就是拿到一个连接redis的client:
redis.NewClient()
当然也可以根据这个client建立连接池:
pool:=goredis.NewPool(client)  (redis本身连接就会维持一套连接池)
根据连接池创建一个redsync:
rs:=redsync.New(pool)
定义红锁的名称,也就是雨荨有多个红锁:
muName:="test"
mutex:=rs.NewMutex(muName)
在业务逻辑中也就是redis的资源 命令操作时上锁和解锁:
mutex.Lock()
mutex.Unlock()







github.com/go-redsync/redsync/v4
github.com/go-redsync/redsync/v4/redis/goredis/v8