库存服务:
浏览器的等请求到商品服务,操作完后其实是设置了库存的,也就是商品服务会调用库存服务
订单服务会预扣库存和归还库存 支付服务会扣库存(支付宝调用支付服务)
库存一般提供给其他rpc服务调用,自身不用设置api层





并发情况下库存比如扣减库存容易出现问题,其实就是并发修改stock,可能多个调用这个库存微服务去扣减库存
解决并发问题,最原始的方式就是加锁
实际上就是要解决同一时间只能有一个服务操作同一件商品的库存,服务完成后再到别的进程处理
比如同时两个订单服务同时查询库存发现都是100件,都扣减1,大家更新库存都是99,而实际上应该是98,也就是卖两件,也就是一件商品当成出售两次,超卖
解决方式就是加分布式锁,得我这个订单服务查询库存更新库存完成后,再到别的进程处理
也就是让各个进程代码开始直接先去获取一把分布式锁,获取到锁的类似拿到令牌,才能进行后续的逻辑,服务完成释放锁
可以直接在服务的代码逻辑中加锁,但问题是这不是代码本身的goroutine,二十多个进程,每个进程(协程都获取一次这个局部锁,对自身并发有约束,但是对多进程并发没意义)
所以要在代码外部定义全局锁,然后服务代码逻辑中使用,在查询更新等数据库操作之前上锁,如果由事务要在事务之后释放锁
局部锁也就是服务代码中定义的锁除了没有多进程并发调用这个服务没有约束里,因为是服务代码中定义的,所以要共用一把锁(所以grpc并不是只是调用服务代码代码快本身,还有server端的很多内容),还有就是性能消耗问题
那全局锁,实际上使用也是服务代码中使用,比如上锁,锁是由资源消耗的,高并发情况下,还是获取大量的锁,性能消耗,比如请求的是多个商品的库存处理,这里就不是同一个临界资源stock了,而是不同商品所以都能获得相应的锁(一把实际的锁其实是针对某相同的一个或多个临界资源护或者说共享变量 共享内存地址被多个进程(协程)进行处理),那么就是同时多个进程都能对一把全局锁进行上锁,性能问题就来了
解决办法就是池化全局锁
那么这种锁在分布式系统中有什么问题呢,比如这个server端服务在多个机器上都有,也就是多个实例,而锁是依赖操作系统提供了,所以同一个机器上的多个服务协程调用可以通过同一把锁来解决,但不同机器上就不能通过这样一把锁来解决了,因为是同一类server端服务,很有可能同一个rpc是共用一个数据库,这时候不同机器还是存在资源竞争问题
单机锁就不够了,需要分布式锁,也就是在多个库存服务之间有个独立的分布式锁
也就是库存服务1中有服务被调用,不论是客户端多进程来调用,还是服务本身多goroutine运行,只要库存服务1在运行,也就是获取了分布式锁,那么别的库存服务就要等待
实际上也不用多机,哪怕是一台主机上多个进程,多个pod,多个容器都应该使用分布式锁才有效



注意这里通过channel并不能很好处理,channel是不同goroutine之间传递信息,同步操作,而这里是不同的进程了,channel适合自身的代码内的并发设计,不同进程要使用分布式锁(可以将数据库中的数据拿到内存中,也就是一个变量,channel来协调多个goroutine来设置这个变量)
比如定义一个变量int,一个channel int,gorouine中使用这个变量,修改这个变量,将值写入channel,然后主goroutine读取channel值给变量
或者直接加锁
缓冲通道实际上就是多个缓冲,由元素就不阻塞,本质还是channel,同一时间只有一个goroutine在处理




